{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sathua.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GFekMVlvHLzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0801ec1f-456c-4942-ea8c-69e186e6b102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "cB4RLedcMDIA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "import tensorboard\n",
        "print(tensorboard.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Odv8y7hHgrk",
        "outputId": "f926c7ef-971d-4d6d-a96e-269155805d5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frozen_graph = 'opencv_face_detector_uint8.pb'\n",
        "output_graph = \"frozen_inference_graph_dnn.pb\"\n",
        "LOGDIR = '/content/logs'\n",
        "# Clear any logs from previous runs\n",
        "%cd /content/\n",
        "!rm -rf ./logs/ "
      ],
      "metadata": {
        "id": "-hDOA0taJG4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15c33e7-22c9-4b74-9220-0562e2e8d9fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.tools.graph_transforms import TransformGraph\n",
        "from tensorflow.core.framework import graph_pb2\n",
        "import copy\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gjLtvHOR0pAq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph(filename):\n",
        "    print(f'load_graph {filename}')\n",
        "    graph_def = tf.GraphDef()\n",
        "    with tf.gfile.FastGFile(filename, 'rb') as f:\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    return graph_def\n"
      ],
      "metadata": {
        "id": "FQzdybZe0tQU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_graph(input_graph, output_graph=None):\n",
        "    \"\"\" Use to run different transform function on the input graph and generate a output graph. \"\"\"\n",
        "    print(input_graph)\n",
        "    if isinstance(input_graph, graph_pb2.GraphDef):\n",
        "        graph_def = input_graph\n",
        "    else:\n",
        "        graph_def = load_graph(input_graph)\n",
        "\n",
        "    print(\"swa\")\n",
        "    # new_graph_def = TransformGraph(graph_def, ['input_placeholder/input_image'], ['predicated_output'],\n",
        "    #                                ['strip_unused_nodes(type=float, shape=\"1,28,28,1\")',\n",
        "    #                                 'remove_nodes(op=Identity, op=CheckNumerics, op=Switch)',\n",
        "    #                                 'fold_constants(ignore_errors=true)', 'fold_batch_norms', 'fold_old_batch_norms',\n",
        "    #                                 'sort_by_execution_order'])\n",
        "    new_graph_def = TransformGraph(graph_def, ['input_placeholder/input_image'], [],\n",
        "                                   ['strip_unused_nodes(type=float, shape=\"1,28,28,1\")',\n",
        "                                    'remove_nodes(op=Identity, op=CheckNumerics, op=Switch)',\n",
        "                                    'fold_constants(ignore_errors=true)', 'fold_batch_norms', 'fold_old_batch_norms',\n",
        "                                    'sort_by_execution_order'])\n",
        "\n",
        "    if output_graph == None:\n",
        "        return new_graph_def\n",
        "\n",
        "    # save new graph\n",
        "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "        f.write(new_graph_def.SerializeToString())\n",
        "\n",
        "    # tf.io.write_graph(od_graph_def, \"\", output_graph, as_text=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "WjAebxF50ydJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_constant(input_graph, output_graph=None):\n",
        "    \"\"\" Convert the placeholders in graph to constant nodes. \"\"\"\n",
        "    if isinstance(input_graph, graph_pb2.GraphDef):\n",
        "        graph_def = input_graph\n",
        "    else:\n",
        "        graph_def = load_graph(input_graph)\n",
        "\n",
        "    keep_prob = tf.constant(1.0, dtype=tf.float32, shape=[], name='keep_prob')\n",
        "    weight_factor = tf.constant(1.0, dtype=tf.float32, shape=[], name='weight_factor')\n",
        "    is_training = tf.constant(False, dtype=tf.bool, shape=[], name='is_training')\n",
        "\n",
        "    new_graph_def = graph_pb2.GraphDef()\n",
        "\n",
        "    for node in graph_def.node:\n",
        "        if node.name == 'keep_prob':\n",
        "            new_graph_def.node.extend([keep_prob.op.node_def])\n",
        "\n",
        "        elif node.name == 'weight_factor':\n",
        "            new_graph_def.node.extend([weight_factor.op.node_def])\n",
        "\n",
        "        elif node.name == 'is_training':\n",
        "            new_graph_def.node.extend([is_training.op.node_def])\n",
        "\n",
        "        else:\n",
        "            new_graph_def.node.extend([copy.deepcopy(node)])\n",
        "\n",
        "    if output_graph == None:\n",
        "        return new_graph_def\n",
        "\n",
        "    # save new graph\n",
        "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "        f.write(new_graph_def.SerializeToString())\n"
      ],
      "metadata": {
        "id": "jaePXHrm02Gh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_batch_normalization(input_graph, output_graph=None):\n",
        "    \"\"\" Optimize the batch normalization block. \"\"\"\n",
        "    if isinstance(input_graph, graph_pb2.GraphDef):\n",
        "        graph_def = input_graph\n",
        "    else:\n",
        "        graph_def = load_graph(input_graph)\n",
        "\n",
        "    new_graph_def = graph_pb2.GraphDef()\n",
        "    unused_attrs = ['is_training']  # Attributes of FusedBatchNorm. Not needed during inference.\n",
        "\n",
        "    # All the node names are specific to my ocr model.\n",
        "    # All the input names are found manually from tensorboard\n",
        "    for node in graph_def.node:\n",
        "        modified_node = copy.deepcopy(node)\n",
        "        if node.name.startswith(\"conv\"):  # True for Convolutional Layers\n",
        "            starting_name = \"\"\n",
        "            if node.name.startswith(\"conv1\"):\n",
        "                starting_name = \"conv1\"\n",
        "\n",
        "            elif node.name.startswith(\"conv2\"):\n",
        "                starting_name = \"conv2\"\n",
        "\n",
        "            elif node.name.startswith(\"conv3\"):\n",
        "                starting_name = \"conv3\"\n",
        "\n",
        "            elif node.name.startswith(\"conv4\"):\n",
        "                starting_name = \"conv4\"\n",
        "\n",
        "            # Do not add the cond block and its child nodes.\n",
        "            # This is only needed during training.\n",
        "            if \"cond\" in node.name and not node.name.endswith(\"FusedBatchNorm\"):\n",
        "                continue\n",
        "\n",
        "            if node.op == \"FusedBatchNorm\" and node.name.endswith(\"FusedBatchNorm\"):\n",
        "                if bool(starting_name):\n",
        "                    # Changing the name to remove one block hierarchy and changing inputs.\n",
        "                    modified_node.name = \"{0}/{0}/batch_norm/FusedBatchNorm\".format(starting_name)\n",
        "                    modified_node.input[0] = \"{}/Conv2D\".format(starting_name)\n",
        "                    modified_node.input[1] = \"{}/batch_norm/gamma\".format(starting_name)\n",
        "                    modified_node.input[2] = \"{}/batch_norm/beta\".format(starting_name)\n",
        "                    modified_node.input[3] = \"{}/batch_norm/moving_mean\".format(starting_name)\n",
        "                    modified_node.input[4] = \"{}/batch_norm/moving_variance\".format(starting_name)\n",
        "\n",
        "                    # Deleting unused attributes\n",
        "                    for attr in unused_attrs:\n",
        "                        if attr in modified_node.attr:\n",
        "                            del modified_node.attr[attr]\n",
        "\n",
        "            if node.name.endswith('activation'):\n",
        "                if bool(starting_name):\n",
        "                    modified_node.input[0] = \"{0}/{0}/batch_norm/FusedBatchNorm\".format(starting_name)\n",
        "\n",
        "        elif node.name.startswith(\"fc\") or node.name.startswith(\"logits\"):  # True for fully connected layers\n",
        "            starting_name = \"\"\n",
        "            if node.name.startswith(\"fc1\"):\n",
        "                starting_name = \"fc1\"\n",
        "\n",
        "            elif node.name.startswith(\"fc2\"):\n",
        "                starting_name = \"fc2\"\n",
        "\n",
        "            elif node.name.startswith(\"logits\"):\n",
        "                starting_name = \"logits\"\n",
        "\n",
        "            # Do not add cond, cond_1 and moments block of batch normalization\n",
        "            if \"cond\" in node.name or \"moments\" in node.name:\n",
        "                continue\n",
        "\n",
        "            # Change input of batchnorm/add\n",
        "            if node.name.endswith('batchnorm/add'):\n",
        "                modified_node.input[0] = \"{}/batch_norm/moving_variance\".format(starting_name)\n",
        "                modified_node.input[1] = \"{0}/{0}/batch_norm/batchnorm/add/y\".format(starting_name)\n",
        "\n",
        "            if node.name.endswith('batchnorm/mul_2'):\n",
        "                modified_node.input[0] = \"{0}/{0}/batch_norm/batchnorm/mul\".format(starting_name)\n",
        "                modified_node.input[1] = \"{}/batch_norm/moving_mean\".format(starting_name)\n",
        "\n",
        "        new_graph_def.node.extend([modified_node])\n",
        "\n",
        "    if output_graph == None:\n",
        "        return new_graph_def\n",
        "\n",
        "    # save the graph\n",
        "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "        f.write(new_graph_def.SerializeToString())"
      ],
      "metadata": {
        "id": "75Ub5dz206Y9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_dropout(input_graph, output_graph=None):\n",
        "    \"\"\" Remove the dropout block from the model. \"\"\"\n",
        "    if isinstance(input_graph, graph_pb2.GraphDef):\n",
        "        graph_def = input_graph\n",
        "    else:\n",
        "        graph_def = load_graph(input_graph)\n",
        "\n",
        "    new_graph_def = graph_pb2.GraphDef()\n",
        "\n",
        "    for node in graph_def.node:\n",
        "        modified_node = copy.deepcopy(node)\n",
        "        if node.name.startswith('dropout1') or node.name.startswith('dropout2'):\n",
        "            continue\n",
        "\n",
        "        if node.name == \"fc2/fc2/batch_norm/batchnorm/mul_1\":\n",
        "            modified_node.input[0] = \"mul\"\n",
        "            modified_node.input[1] = \"fc2/weights\"\n",
        "\n",
        "        if node.name == \"logits/logits/batch_norm/batchnorm/mul_1\":\n",
        "            modified_node.input[0] = \"fc2/activation\"\n",
        "            modified_node.input[1] = \"logits/weights\"\n",
        "\n",
        "        new_graph_def.node.extend([modified_node])\n",
        "\n",
        "    if output_graph == None:\n",
        "        return new_graph_def\n",
        "\n",
        "    # save the graph\n",
        "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "        f.write(new_graph_def.SerializeToString())\n"
      ],
      "metadata": {
        "id": "vSMFvEVE0-U0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_def = transform_graph(frozen_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56BTf57e1SOE",
        "outputId": "8edbf973-b6fe-4fd4-f366-2e3d60ca0b8d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opencv_face_detector_uint8.pb\n",
            "load_graph opencv_face_detector_uint8.pb\n",
            "swa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_def = convert_to_constant(graph_def)\n"
      ],
      "metadata": {
        "id": "GHBae4A84YkR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_def = optimize_batch_normalization(graph_def)"
      ],
      "metadata": {
        "id": "nxHaX0wJ4bzA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_def = transform_graph(graph_def)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oefshda04hq2",
        "outputId": "9f944a86-d249-402e-f082-f33dd1b002d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "swa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dropout(graph_def, output_graph)"
      ],
      "metadata": {
        "id": "-b0SOhIf4lMC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_dnn_module():\n",
        "    \"\"\" Function to test OpenCV DNN module. \"\"\"\n",
        "    model = 'frozen_inference_graph_dnn.pb'\n",
        "    net = cv2.dnn.readNet(model)\n",
        "    img = cv2.imread('tv24horas_2022_01_06_10_frame_124425.png')\n",
        "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    imgGray = imgGray.astype(np.uint8)\n",
        "    blob = cv2.dnn.blobFromImage(imgGray, 1.0, (28,28), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    output = net.forward()\n",
        "    print(output)"
      ],
      "metadata": {
        "id": "nPkkQgcL7Y_q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dnn_module()"
      ],
      "metadata": {
        "id": "xckpnS5k7iEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}